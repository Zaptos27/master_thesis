{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# set the legend frame\n",
    "plt.rcParams['legend.frameon'] = True\n",
    "plt.rcParams['legend.facecolor'] = 'white'\n",
    "plt.rcParams['legend.edgecolor'] = 'black'\n",
    "plt.rcParams['legend.framealpha'] = 1\n",
    "\n",
    "# set the line width\n",
    "plt.rcParams['lines.linewidth'] = 2.0\n",
    "\n",
    "# set the point size\n",
    "plt.rcParams['lines.markersize'] = 8\n",
    "\n",
    "# set the error bar capsize\n",
    "plt.rcParams['errorbar.capsize'] = 5\n",
    "\n",
    "# set the font size\n",
    "plt.rcParams['font.size'] = 16\n",
    "\n",
    "# set the figure dpi\n",
    "plt.rcParams['figure.dpi'] = 192\n",
    "\n",
    "# set the save figure format\n",
    "plt.rcParams['savefig.format'] = 'pdf'\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"llvm\", \"opencl\", \"cuda\"]\n",
    "networks = [\"mlp\", \"mlp_conv\", \"separable_conv1d\", \"separable_conv2d\", \"mlp_wide\", \"mlp_deep\", \"mlp_deep_wide\", \"conv1d\", \"conv2d\", \"depthwise_conv1d\", \"lstm\", \"mlp_piecewise\", \"mlp_piecewise2\", \"mlp_big\", \"mlp_small\"]\n",
    "old_cluster = 7476309\n",
    "version = \"0.0.0\"\n",
    "old_cluster2 = 7473664\n",
    "\n",
    "if version[2] == \"0\":\n",
    "    windowsize = 3\n",
    "else:\n",
    "    windowsize = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best 0.1532872783238921 for mlp llvm\n",
      "Best 0.08942271321614582 for mlp opencl\n",
      "Best 0.08782820476955837 for mlp cuda\n",
      "Found latency in hls4ml/mlp_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 0.6020073207855224 for mlp_conv llvm\n",
      "Best 0.13429278218068802 for mlp_conv opencl\n",
      "Best 0.12966323141665878 for mlp_conv cuda\n",
      "Found latency in hls4ml/mlp_conv_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 0.27195650590931536 for separable_conv1d llvm\n",
      "Best 0.10451301635608011 for separable_conv1d opencl\n",
      "Best 0.10440406438528439 for separable_conv1d cuda\n",
      "Best 0.3787093506167633 for separable_conv2d llvm\n",
      "Best 0.10423617994805345 for separable_conv2d opencl\n",
      "Best 0.09983665528407851 for separable_conv2d cuda\n",
      "Best 0.6190702731045811 for mlp_wide llvm\n",
      "Best 0.34331463989257816 for mlp_wide opencl\n",
      "Best 0.34136137008666995 for mlp_wide cuda\n",
      "Found latency in hls4ml/mlp_wide_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 0.24814608743849467 for mlp_deep llvm\n",
      "Best 0.1744708319769965 for mlp_deep opencl\n",
      "Best 0.17269424404568143 for mlp_deep cuda\n",
      "Found latency in hls4ml/mlp_deep_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 0.8946845764160157 for mlp_deep_wide llvm\n",
      "Best 0.7376172985839843 for mlp_deep_wide opencl\n",
      "Best 0.7381293069839476 for mlp_deep_wide cuda\n",
      "Found latency in hls4ml/mlp_deep_wide_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 0.607790061378479 for conv1d llvm\n",
      "Best 0.07799382537841795 for conv1d opencl\n",
      "Best 0.06928813074360723 for conv1d cuda\n",
      "Found latency in hls4ml/conv1d_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 0.2996304938583169 for conv2d llvm\n",
      "Best 0.21027441584074333 for conv2d opencl\n",
      "Best 0.11720615141732353 for conv2d cuda\n",
      "Best 0.23477231256961822 for depthwise_conv1d llvm\n",
      "Best 0.13286070083069443 for depthwise_conv1d opencl\n",
      "Best 0.12991370371034622 for depthwise_conv1d cuda\n",
      "Best 0.758290625665838 for lstm llvm\n",
      "Best 0.45815663696289066 for lstm opencl\n",
      "Best 0.45287069053649903 for lstm cuda\n",
      "Found latency in hls4ml/lstm_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 0.445934171447754 for mlp_piecewise llvm\n",
      "Best 0.47212164184570315 for mlp_piecewise opencl\n",
      "Best 0.4712468811416627 for mlp_piecewise cuda\n",
      "Best 0.6531500281906127 for mlp_piecewise2 llvm\n",
      "Best 0.4780222375488281 for mlp_piecewise2 opencl\n",
      "Best 0.4722868785095215 for mlp_piecewise2 cuda\n",
      "Best 0.6390300439834594 for mlp_big llvm\n",
      "Best 0.4513897619628907 for mlp_big opencl\n",
      "Best 0.4469054225158691 for mlp_big cuda\n",
      "Found latency in hls4ml/mlp_big_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n",
      "Best 3.7172342592921406 for mlp_small llvm\n",
      "Best 0.0011690285914014971 for mlp_small cuda\n",
      "Found latency in hls4ml/mlp_small_0.0.0_7473664_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\n"
     ]
    }
   ],
   "source": [
    "best = []\n",
    "fpga = []\n",
    "for i, network in enumerate(networks):\n",
    "    fig , ax = plt.subplots(figsize=(10, 6))\n",
    "    for j, target in enumerate(targets):\n",
    "        files = glob.glob(f'../../final/benchmarks/{network}-*{version}-{target}-{old_cluster}*d.perf')\n",
    "        if files == []:\n",
    "            best.append(np.nan)\n",
    "            continue\n",
    "        #files = glob.glob(f'../../final/benchmarks/{network}-*-{target}-{old_cluster}*d.perf')\n",
    "        #print(files)\n",
    "        batch_size = []\n",
    "        data = []\n",
    "        for file in files:\n",
    "            data.append(np.loadtxt(file, delimiter=','))\n",
    "            #print(f\"Loaded {file}\")\n",
    "            batch_size.append(int(re.findall(r'-\\d+', file)[0][1:]))\n",
    "            #print(f\"Batch size {batch_size[-1]}\")\n",
    "        me = np.array([np.mean(d) for d in data])\n",
    "        st = np.array([np.std(d) for d in data])\n",
    "        batch_size = np.array(batch_size)\n",
    "        ax.plot(batch_size, me/batch_size*1e6, ['s', 'o', '*'][j], label=target)\n",
    "        # Make best of each target in a box and place it at 10 and bachsize of 4096\n",
    "        ax.text(4096, np.exp(j*0.35+1), fr\"{target}: {np.amin(me/batch_size*1e6):.2f} $\\mu$ s\", ha='center', va='center', bbox=dict(facecolor='white', edgecolor='black', alpha=1))\n",
    "        best.append(np.amin(me/batch_size*1e6))\n",
    "        print(f\"Best {np.amin(me/batch_size*1e6)} for {network} {target}\")\n",
    "    if os.path.exists(f\"hls4ml/{network}_{version}_{old_cluster2}_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\"):\n",
    "        hls4ml_rpt = f\"hls4ml/{network}_{version}_{old_cluster2}_hls4ml_prj/myproject_prj/solution1/syn/report/myproject_csynth.rpt\"\n",
    "        # Find the max latency\n",
    "        with open(hls4ml_rpt) as f:\n",
    "            for j, line in enumerate(f):\n",
    "                if \"+ Latency:\" in line:\n",
    "                    # Get the latency 5 lines down\n",
    "                    print(f\"Found latency in {hls4ml_rpt}\")\n",
    "                    for _ in range(6):\n",
    "                        line = next(f)\n",
    "                    latency = re.findall(r'\\d+', line)[-1]\n",
    "                    ax.plot([0,65565], [int(latency)*5e-9*1e6, int(latency)*5e-9*1e6], 'r', label=\"FPGA\")\n",
    "                    ax.text(4096, np.exp(3*0.35+1), fr\"FPGA: {int(latency)*5e-9*1e6:.2f} $\\mu$ s\", ha='center', va='center', bbox=dict(facecolor='white', edgecolor='black', alpha=1))\n",
    "                    fpga.append(int(latency)*5e-9*1e6)\n",
    "    else:\n",
    "        fpga.append(np.nan)\n",
    "    #ax.plot(batch_size, np.ones_like(batch_size)*44*5e-9, 'r', label=\"FPGA\")\n",
    "    title = f\"{network} performance for window size of {windowsize}\" + (\" inside-out\" if version[-1] == \"0\" else \" outside-in\") +  (\" with float32\" if old_cluster == 7476308 else \" with float16\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(0.6, 50000)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"Batch size\")\n",
    "    ax.set_ylabel(r\"Time per sample ($\\mu$s)\")\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    if old_cluster == 7476308:\n",
    "        plt.savefig(f\"../../final/runtime/{network}_runtime_{version}.pdf\")\n",
    "    else:\n",
    "        plt.savefig(f\"../../final/runtime/{network}_runtime_{version}_fp16.pdf\")\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_272793/1980051621.py:15: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(networks, rotation=45, ha=\"right\")\n"
     ]
    }
   ],
   "source": [
    "#make a bar plot of the stds using seaborn\n",
    "import pandas as pd\n",
    "data = []\n",
    "for i, network in enumerate(networks):\n",
    "    for j, target in enumerate(targets):\n",
    "        data.append([network, target, best[i*3+j]])\n",
    "    if not np.isnan(fpga[i]):\n",
    "        data.append([network, \"FPGA\", fpga[i]])\n",
    "df = pd.DataFrame(data, columns=['Network', 'Target', 'Time'])\n",
    "fig, ax = plt.subplots(1, figsize=(18, 6))\n",
    "sns.barplot(df, x=\"Network\", y=\"Time\", ax=ax, linewidth=1.5, edgecolor=\"black\", hue=\"Target\")\n",
    "ax.set_title(f\"Best performance per network for window size of {windowsize}\"+ (\" inside-out\" if version[2] == \"0\" else \" outside-in\") + (\" with float32\" if old_cluster == 7476308 else \" with float16\"), fontsize=20)\n",
    "ax.set_xlabel(\"Network\", fontsize=18)\n",
    "ax.set_ylabel(r\"Time per sample ($\\mu$s)\", fontsize=18)\n",
    "ax.set_xticklabels(networks, rotation=45, ha=\"right\")\n",
    "ax.grid()\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.1f'), \n",
    "                (p.get_x() + p.get_width() / 2., np.amax([np.amin([p.get_height(),0.95]),0.1])), \n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, -10), \n",
    "                textcoords = 'offset points',\n",
    "                color='white', rotation=90)\n",
    "plt.tight_layout()\n",
    "# set the size of the labels\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "sns.despine(top=True, right=False)\n",
    "ax.set_ylim(0,1)\n",
    "#plt.show()\n",
    "if old_cluster == 7476308:\n",
    "    plt.savefig(f\"../../final/runtime/best_performance_{version}.pdf\", bbox_inches='tight')\n",
    "else:\n",
    "    plt.savefig(f\"../../final/runtime/best_performance_{version}_fp16.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trackml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
