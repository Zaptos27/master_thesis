executable              = benchmark_mlp_onnx.sh
arguments               = $(ClusterId) $(ProcId)
output                  = benchmark_onnx.$(ClusterId).$(ProcId).out
error                   = benchmark_onnx.$(ClusterId).$(ProcId).err
log                     = benchmark_onnx.$(ClusterId).log
transfer_input_files    = models,onnx_testrun.py
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
request_GPUs = 1
request_CPUs = 20
requirements = regexp("H100", TARGET.GPUs_DeviceName)
+JobFlavour = "tomorrow"  
queue  
